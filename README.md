<<<<<<< Updated upstream
# **MACHINE LEARNING PROJECT:** CUSTOMER SEGMENTATION

## Members
```bash
Matteo Ferraresi - 
Giulia Formiconi -  
Mohamed Ali Ben Belhassen - 273771
```

# **INTRODUCTION**

We are studying a large company's subsidiary resident in Brazil, and the goal is to identify the ideal partitions and assign each user in the dataset to one of them. The data we have concerns users, sellers, payments, among other things. 

First of all, we started by performing an exploratory data analysis (EDA). This technique is used to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods, as you will see.

Following, we started building our model using the RFM analysis for customer segmentation.
- **R** stands for **Recency value** : refers to the time since a customer’s last purchase.
- **F** stands for **Frequency value** :  refers to the number of times a customer has made a purchase.
- **M** stands for **Monetary value** : refers to the total amount a customer has spent purchasing products.  

We then plotted the RFM dataset to have a better look and we deduce that we have a positive correlation in between frequency and monetary value, due to the fact that the more a customer purchases the more he spends in total; so the more frequency value goes up, the more monetary value will go up too.

After performing an EDA and preprocessing the dataset, we used the following methods based on RFM that will help us explore data, plot it, analyze it, and have a more clear understanding of what's going on:
```bash
1. K-means
2. Hierarchical Clustering (HC)
3. Spectral Clustering
4. EM Clustering using GMM
5. BIRCH
```

Let's look into these algorithms deeper.

# **ALGORITHMS**

We started by calculating the RFM. We found the first and last date of purchase:

![Min,Max](https://raw.githubusercontent.com/MatteoFerraresi/267161/main/images/minmax.png)

diventato 1 col merge e rimozione last purchase date e customer id poi standardizzato/scalato 


# **EXPERIMENTAL DESIGN**


# **RESULTS**


=======
# **MACHINE LEARNING PROJECT:** CUSTOMER SEGMENTATION

## Members
```bash
Matteo Ferraresi - 
Giulia Formiconi -  
Mohamed Ali Ben Belhassen - 273771
```

# **INTRODUCTION**

We are studying a large company's subsidiary resident in Brazil, and the goal is to identify the ideal partitions and assign each user in the dataset to one of them. The data we have concerns users, sellers, payments, among other things. 

First of all, we started by performing an exploratory data analysis (EDA). This technique is used to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods, as you will see.

Following, we started building our model using the RFM analysis for customer segmentation.
- **R** stands for **Recency value** : refers to the time since a customer’s last purchase.
- **F** stands for **Frequency value** :  refers to the number of times a customer has made a purchase.
- **M** stands for **Monetary value** : refers to the total amount a customer has spent purchasing products.  

We then plotted the RFM dataset to have a better look and we deduce that we have a positive correlation in between frequency and monetary value, due to the fact that the more a customer purchases the more he spends in total; so the more frequency value goes up, the more monetary value will go up too.

After performing an EDA and preprocessing the dataset, we used the following methods based on RFM that will help us explore data, plot it, analyze it, and have a more clear understanding of what's going on:
```bash
1. K-means
2. Hierarchical Clustering (HC)
3. Spectral Clustering
4. EM Clustering using GMM
5. BIRCH
```

Let's look into these algorithms deeper.

# **ALGORITHMS**

We started by calculating the RFM. We found the first and last date of purchase:

![Min,Max](https://raw.githubusercontent.com/MatteoFerraresi/267161/main/images/minmax.png)

diventato 1 col merge e rimozione last purchase date e customer id poi standardizzato/scalato 


# **EXPERIMENTAL DESIGN**


# **RESULTS**


>>>>>>> Stashed changes
# **CONCLUSIONS**